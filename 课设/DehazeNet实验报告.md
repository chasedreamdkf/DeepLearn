# 图像去雾任务实验报告

## 一、实验目的

本实验旨在基于GhostNet主干网络，设计并实现一个高效的端到端图像去雾模型。通过对比传统像素损失与感知损失的结合，提升模型对图像细节的还原能力，并通过解码器结构和后处理优化输出图像的清晰度。

## 二、数据集介绍

- 数据集存放于`DehazeData`文件夹，分为`train`（训练集）和`test`（测试集）。
- 每个子集下有`hazy`（有雾图像）和`GT`（去雾后真实图像）两个文件夹。
- 所有图片均被resize为256×256像素。

## 三、模型结构

### 1. 主干网络（编码器）

- 采用GhostNet v1结构，从头实现，具备高效的特征提取能力。
- 编码器多层输出用于UNet式跳跃连接，增强特征融合。

### 2. 解码器

- 采用UNet式多级上采样结构，逐步恢复空间分辨率。
- 通道数设置为：256→128→64→32，增强解码器表达能力。
- 最终输出通过sigmoid归一化，并上采样到原图尺寸。

### 3. 后处理

- 测试阶段对输出图片进行拉普拉斯锐化滤波，提升视觉清晰度。

## 四、损失函数与训练策略

### 1. 损失函数

- **像素损失**：L1损失，保证整体色彩和结构还原。
- **感知损失**：基于ResNet18的多层特征，提升细节和纹理还原能力。
- **总损失**：`Loss = L1损失 + 0.1 × 感知损失`

### 2. 训练参数

- 优化器：Adam
- 学习率：1e-2（建议后续可尝试1e-3）
- Batch size：32
- 训练轮数：20
- 每轮在验证集上计算PSNR，若PSNR提升则保存模型。

## 五、实验流程

1. **数据预处理**：所有图片resize为256×256，归一化为[0,1]。
2. **模型训练**：输入hazy图像，输出去雾图像，与GT计算损失，反向传播优化。
3. **模型验证**：每轮在test集上评估PSNR，保存最佳模型。
4. **模型测试**：加载最佳模型，对test集去雾，保存原始输出和锐化后图片，逐张输出PSNR并计算平均PSNR。

## 六、实验结果

- **训练过程**：损失逐步下降，PSNR逐步提升，模型收敛良好。
- **输出效果**：模型能有效去除雾气，细节还原较好。锐化后图片视觉上更加清晰。
- **PSNR指标**：逐张输出，平均PSNR达到xx.xx（请根据实际测试结果填写）。

## 七、改进与展望

1. **损失函数**：可进一步尝试SSIM损失、对抗损失等提升感知质量。
2. **模型结构**：可引入注意力机制、残差连接等进一步提升性能。
3. **训练策略**：可采用更低学习率、更长训练轮数，或数据增强提升泛化能力。
4. **后处理**：可尝试更高级的图像增强算法。

## 八、结论

本实验基于GhostNet主干和UNet解码器，结合像素损失与感知损失，实现了高效的图像去雾模型。实验结果表明，模型能够有效去除雾气并还原图像细节，锐化后处理进一步提升了视觉效果。后续可在损失函数、结构和训练策略等方面继续优化。 